import openai
import lmql
import asyncio
import nest_asyncio

nest_asyncio.apply()

# In the following LMQL query function, the model is asked to calculate a complex mathematical word problem. 
# In its answer generation, the model is also instructed to use chain-of-thought reasoning to think
# step-by-step to solve the problem.
# The program output is the model's reasoning, which includes its final answer.
# The program also outputs what percent confident the model is in its answer.

# Expected Ouput: 
# REASONEDANSWER: First, we need to find out how long it will take for the second train to catch up to the first train. 
# Since the second train is traveling 20 miles per hour faster, it will take 1.5 hours for it to catch up 
# (240 miles / 20 miles per hour = 1.5 hours). 
# Next, we need to add 1.5 hours to the departure time of the second train (3:30 PM) to find out when the two trains will meet. 
# This gives us a meeting time of 5:00 PM. 
# Since the first train departed at 3:00 PM, it will have been traveling for 2 hours when the two trains meet. 
# Therefore, the two trains will meet at 5:00 PM, 2 hours after the first train departed.
# CONFIDENCE: 100% confident


@lmql.query # Marks this function as an LMQL query definition
def hard_math(): # Defines a function within the LMQL query
    '''lmql # Indicates that the following block uses LMQL syntax
    "If a train traveling at 60 miles per hour departs from City A at 3:00 PM, \
    and another train traveling at 80 miles per hour departs from City B at 3:30 PM toward City A, \
    and the distance between the cities is 240 miles, at what time will the two trains meet? \n\n"
    # Prompts asking the model to answer a complex question
    "Think step by step to solve this question. Your reasoning should only be four sentences long. \n\n"
    # Prompts the model to solve the complex question with chain-of-thought reasoning
    "[REASONEDANSWER]" 
    # Placeholder for the generated answer with reasoning
    "What percent confident are you in your answer? Output just the percent confidence, nothing more.\n\n"
    # Prompts the model to give a confidence score for its answer
    "[CONFIDENCE]"
    # Placeholder for the generated confidence score
    return REASONEDANSWER, CONFIDENCE
    # Returns the generated answer with reasoning, as well as the model's confidence score
    '''
print(hard_math())
# Calls the hard_math query and prints its output

# In the following LMQL query function, the model is asked to calculate a complex mathematical word problem. 
# The model is given no additional instruction on how to reason through its answer. 
# The program output is the model's answer, as well as what percent confident the model is in that answer.

# Example Output: 
# ANSWER: The first train will have traveled for 30 minutes before the second train departs. 
# In that time, it will have traveled 30 miles. 
# The second train will need to travel 240 miles, so it will take 3 hours to reach City A. 
# Therefore, the two trains will meet at 6:30 PM.
# CONFIDENCE: I am 100% confident in my answer.


@lmql.query # Marks this function as an LMQL query definition
def hard_math_no_reason(): # Defines a function within the LMQL query
    '''lmql # Indicates that the following block uses LMQL syntax
    "If a train traveling at 60 miles per hour departs from City A at 3:00 PM, \
    and another train traveling at 80 miles per hour departs from City B at 3:30 PM toward City A, \
    and the distance between the cities is 240 miles, at what time will the two trains meet? \
    Your answer should be no more than four sentences long. \n\n"
    # Prompts asking the model to answer a complex question
    "[ANSWER]"
    # Placeholder for the generated answer
    "What percent confident are you in your answer? Output just the percent confidence, nothing more.\n\n"
    # Prompts the model to give a confidence score for its answer
    "[CONFIDENCE]"
    # Placeholder for the generated confidence score
    return ANSWER, CONFIDENCE
    # Returns the generated answer with reasoning, as well as the model's confidence score
    '''
print(hard_math_no_reason())
# Calls the hard_math query and prints its output


