import openai
import lmql
import asyncio
import nest_asyncio
import re

nest_asyncio.apply()

@lmql.query
def model_measuring_good():
    '''lmql
    "Review: We had a great stay. Hiking in the mountains was fabulous and the food is really good.\n"
    "Q: What is the underlying sentiment of this review\n"
    "A:[ANALYSIS]" where ANALYSIS in ["good", "bad", "neutral"]
    "Why did you choose that sentiment?\n\n"
    "[REASONING]"
    return ANALYSIS, REASONING
    '''
#print(model_measuring_good())

@lmql.query
def model_measuring_bad():
    '''lmql
    "Review: We had a terrible stay. Hiking in the mountains was so cold and windy and the food is dry and too salty.\n"
    "Q: What is the underlying sentiment of this review\n"
    "A:[ANALYSIS]" where ANALYSIS in ["good", "bad", "neutral"]
    "Why did you choose that sentiment?\n\n"
    "[REASONING]"
    return ANALYSIS, REASONING
    '''
#print(model_measuring_bad())

@lmql.query
def model_measuring_neutral():
    '''lmql
    "Review: We had a fine stay. Hiking in the mountains was okay, nothing special, and the food is mediocre.\n"
    "Q: What is the underlying sentiment of this review\n"
    "A:[ANALYSIS]" where ANALYSIS in ["good", "bad", "neutral"]
    "Why did you choose that sentiment?\n"
    "[REASONING]"
    return ANALYSIS, REASONING
    '''
#print(model_measuring_neutral())

@lmql.query
def confidence_scores():
    '''lmql
    "How tall is Mt. Everest? \n\n"
    "[ANSWER]"
    "On a scale of 1 to 100, how confident are you in that answer? \n\n"
    "[CONFIDENCE]" where INT(CONFIDENCE)
    return ANSWER, CONFIDENCE
    '''
print(confidence_scores())

@lmql.query
def confidence_percent():
    '''lmql
    "What ist the most populous country in the world?\n\n"
    "[ANSWER]"
    "What percent confident are you in that answer? \n\n"
    "[CONFIDENCE]" where INT(CONFIDENCE)
    return ANSWER, CONFIDENCE
    '''
#print(confidence_percent())